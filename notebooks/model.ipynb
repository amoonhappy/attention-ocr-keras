{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bit91d18368432945ea9e9b1e0c8c6ecbd9",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, MaxPooling1D\n",
    "from tensorflow.keras.layers import Input, Dense, Activation\n",
    "from tensorflow.keras.layers import Reshape, Lambda\n",
    "from tensorflow.keras.layers import Add, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop, Adadelta, Adagrad, Adamax, Nadam\n",
    "import numpy as np\n",
    "from imutils import paths\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "import tensorflow as tf\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    loss = K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "    # tf.print(y_pred.shape)\n",
    "    # tf.print(labels.shape)\n",
    "    # tf.print(tf.math.argmax(y_pred, axis=2)[0], summarize=-1, output_stream='file://pred.out')\n",
    "    # tf.print(labels[0], summarize=-1, output_stream='file://label.out')\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(training,img_w,img_h,depth,alphabetLength,absolute_max_string_len):\n",
    "    conv_filters = 16\n",
    "    kernel_size = (3, 3)\n",
    "    pool_size = 2\n",
    "    time_dense_size = 32\n",
    "    rnn_size = 512\n",
    "\n",
    "    act='relu'\n",
    "    if K.image_data_format()=='channels_first':\n",
    "      input_shape=(depth,img_w,img_h)\n",
    "    else:\n",
    "      input_shape=(img_w,img_h,depth)\n",
    "\n",
    "    input_data=Input(name='the_input',shape=input_shape,dtype='float32')\n",
    "    \n",
    "    base_model = tf.keras.applications.InceptionResNetV2(weights='imagenet', include_top=False, input_tensor=input_data)\n",
    "    for l in base_model.layers:\n",
    "        l.trainable = False\n",
    "\n",
    "    inner = Reshape(target_shape=(32,2856), name='reshape')(base_model.get_layer('mixed_6a').output)\n",
    "    inner = Dense(time_dense_size, activation=act, name='dense1')(inner)       \n",
    "\n",
    "    gru_1 = GRU(rnn_size, return_sequences=True,\n",
    "          kernel_initializer='he_normal', name='gru1')(inner)\n",
    "    gru_1b = GRU(rnn_size, return_sequences=True,\n",
    "           go_backwards=True, kernel_initializer='he_normal',\n",
    "           name='gru1_b')(inner)\n",
    "    gru1_merged = Add()([gru_1, gru_1b])\n",
    "\n",
    "    gru_2 = GRU(rnn_size, return_sequences=True,\n",
    "          kernel_initializer='he_normal', name='gru2')(gru1_merged)\n",
    "    gru_2b = GRU(rnn_size, return_sequences=True, go_backwards=True,\n",
    "           kernel_initializer='he_normal', name='gru2_b')(gru1_merged)\n",
    "\n",
    "    # transforms RNN output to character activations:\n",
    "    inner = Dense(alphabetLength, kernel_initializer='he_normal',name='dense2')(Concatenate()([gru_2, gru_2b]))\n",
    "    \n",
    "    y_pred = Activation('softmax', name='softmax')(inner)\n",
    "\n",
    "    labels = Input(name='the_labels', shape=(absolute_max_string_len,), dtype='float32')\n",
    "    input_length = Input(name='input_length', shape=(1,), dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=(1,), dtype='int64')\n",
    "\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "    \n",
    "    if training:\n",
    "        return Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
    "    else:\n",
    "        return Model(inputs=[input_data], outputs=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "________________\nactivation_463 (Activation)     (None, 15, 25, 32)   0           batch_normalization_463[0][0]    \n__________________________________________________________________________________________________\nconv2d_461 (Conv2D)             (None, 15, 25, 32)   10240       block35_7_ac[0][0]               \n__________________________________________________________________________________________________\nconv2d_464 (Conv2D)             (None, 15, 25, 48)   13824       activation_463[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_461 (BatchN (None, 15, 25, 32)   96          conv2d_461[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_464 (BatchN (None, 15, 25, 48)   144         conv2d_464[0][0]                 \n__________________________________________________________________________________________________\nactivation_461 (Activation)     (None, 15, 25, 32)   0           batch_normalization_461[0][0]    \n__________________________________________________________________________________________________\nactivation_464 (Activation)     (None, 15, 25, 48)   0           batch_normalization_464[0][0]    \n__________________________________________________________________________________________________\nconv2d_460 (Conv2D)             (None, 15, 25, 32)   10240       block35_7_ac[0][0]               \n__________________________________________________________________________________________________\nconv2d_462 (Conv2D)             (None, 15, 25, 32)   9216        activation_461[0][0]             \n__________________________________________________________________________________________________\nconv2d_465 (Conv2D)             (None, 15, 25, 64)   27648       activation_464[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_460 (BatchN (None, 15, 25, 32)   96          conv2d_460[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_462 (BatchN (None, 15, 25, 32)   96          conv2d_462[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_465 (BatchN (None, 15, 25, 64)   192         conv2d_465[0][0]                 \n__________________________________________________________________________________________________\nactivation_460 (Activation)     (None, 15, 25, 32)   0           batch_normalization_460[0][0]    \n__________________________________________________________________________________________________\nactivation_462 (Activation)     (None, 15, 25, 32)   0           batch_normalization_462[0][0]    \n__________________________________________________________________________________________________\nactivation_465 (Activation)     (None, 15, 25, 64)   0           batch_normalization_465[0][0]    \n__________________________________________________________________________________________________\nblock35_8_mixed (Concatenate)   (None, 15, 25, 128)  0           activation_460[0][0]             \n                                                                 activation_462[0][0]             \n                                                                 activation_465[0][0]             \n__________________________________________________________________________________________________\nblock35_8_conv (Conv2D)         (None, 15, 25, 320)  41280       block35_8_mixed[0][0]            \n__________________________________________________________________________________________________\nblock35_8 (Lambda)              (None, 15, 25, 320)  0           block35_7_ac[0][0]               \n                                                                 block35_8_conv[0][0]             \n__________________________________________________________________________________________________\nblock35_8_ac (Activation)       (None, 15, 25, 320)  0           block35_8[0][0]                  \n__________________________________________________________________________________________________\nconv2d_469 (Conv2D)             (None, 15, 25, 32)   10240       block35_8_ac[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_469 (BatchN (None, 15, 25, 32)   96          conv2d_469[0][0]                 \n__________________________________________________________________________________________________\nactivation_469 (Activation)     (None, 15, 25, 32)   0           batch_normalization_469[0][0]    \n__________________________________________________________________________________________________\nconv2d_467 (Conv2D)             (None, 15, 25, 32)   10240       block35_8_ac[0][0]               \n__________________________________________________________________________________________________\nconv2d_470 (Conv2D)             (None, 15, 25, 48)   13824       activation_469[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_467 (BatchN (None, 15, 25, 32)   96          conv2d_467[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_470 (BatchN (None, 15, 25, 48)   144         conv2d_470[0][0]                 \n__________________________________________________________________________________________________\nactivation_467 (Activation)     (None, 15, 25, 32)   0           batch_normalization_467[0][0]    \n__________________________________________________________________________________________________\nactivation_470 (Activation)     (None, 15, 25, 48)   0           batch_normalization_470[0][0]    \n__________________________________________________________________________________________________\nconv2d_466 (Conv2D)             (None, 15, 25, 32)   10240       block35_8_ac[0][0]               \n__________________________________________________________________________________________________\nconv2d_468 (Conv2D)             (None, 15, 25, 32)   9216        activation_467[0][0]             \n__________________________________________________________________________________________________\nconv2d_471 (Conv2D)             (None, 15, 25, 64)   27648       activation_470[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_466 (BatchN (None, 15, 25, 32)   96          conv2d_466[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_468 (BatchN (None, 15, 25, 32)   96          conv2d_468[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_471 (BatchN (None, 15, 25, 64)   192         conv2d_471[0][0]                 \n__________________________________________________________________________________________________\nactivation_466 (Activation)     (None, 15, 25, 32)   0           batch_normalization_466[0][0]    \n__________________________________________________________________________________________________\nactivation_468 (Activation)     (None, 15, 25, 32)   0           batch_normalization_468[0][0]    \n__________________________________________________________________________________________________\nactivation_471 (Activation)     (None, 15, 25, 64)   0           batch_normalization_471[0][0]    \n__________________________________________________________________________________________________\nblock35_9_mixed (Concatenate)   (None, 15, 25, 128)  0           activation_466[0][0]             \n                                                                 activation_468[0][0]             \n                                                                 activation_471[0][0]             \n__________________________________________________________________________________________________\nblock35_9_conv (Conv2D)         (None, 15, 25, 320)  41280       block35_9_mixed[0][0]            \n__________________________________________________________________________________________________\nblock35_9 (Lambda)              (None, 15, 25, 320)  0           block35_8_ac[0][0]               \n                                                                 block35_9_conv[0][0]             \n__________________________________________________________________________________________________\nblock35_9_ac (Activation)       (None, 15, 25, 320)  0           block35_9[0][0]                  \n__________________________________________________________________________________________________\nconv2d_475 (Conv2D)             (None, 15, 25, 32)   10240       block35_9_ac[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_475 (BatchN (None, 15, 25, 32)   96          conv2d_475[0][0]                 \n__________________________________________________________________________________________________\nactivation_475 (Activation)     (None, 15, 25, 32)   0           batch_normalization_475[0][0]    \n__________________________________________________________________________________________________\nconv2d_473 (Conv2D)             (None, 15, 25, 32)   10240       block35_9_ac[0][0]               \n__________________________________________________________________________________________________\nconv2d_476 (Conv2D)             (None, 15, 25, 48)   13824       activation_475[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_473 (BatchN (None, 15, 25, 32)   96          conv2d_473[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_476 (BatchN (None, 15, 25, 48)   144         conv2d_476[0][0]                 \n__________________________________________________________________________________________________\nactivation_473 (Activation)     (None, 15, 25, 32)   0           batch_normalization_473[0][0]    \n__________________________________________________________________________________________________\nactivation_476 (Activation)     (None, 15, 25, 48)   0           batch_normalization_476[0][0]    \n__________________________________________________________________________________________________\nconv2d_472 (Conv2D)             (None, 15, 25, 32)   10240       block35_9_ac[0][0]               \n__________________________________________________________________________________________________\nconv2d_474 (Conv2D)             (None, 15, 25, 32)   9216        activation_473[0][0]             \n__________________________________________________________________________________________________\nconv2d_477 (Conv2D)             (None, 15, 25, 64)   27648       activation_476[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_472 (BatchN (None, 15, 25, 32)   96          conv2d_472[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_474 (BatchN (None, 15, 25, 32)   96          conv2d_474[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_477 (BatchN (None, 15, 25, 64)   192         conv2d_477[0][0]                 \n__________________________________________________________________________________________________\nactivation_472 (Activation)     (None, 15, 25, 32)   0           batch_normalization_472[0][0]    \n__________________________________________________________________________________________________\nactivation_474 (Activation)     (None, 15, 25, 32)   0           batch_normalization_474[0][0]    \n__________________________________________________________________________________________________\nactivation_477 (Activation)     (None, 15, 25, 64)   0           batch_normalization_477[0][0]    \n__________________________________________________________________________________________________\nblock35_10_mixed (Concatenate)  (None, 15, 25, 128)  0           activation_472[0][0]             \n                                                                 activation_474[0][0]             \n                                                                 activation_477[0][0]             \n__________________________________________________________________________________________________\nblock35_10_conv (Conv2D)        (None, 15, 25, 320)  41280       block35_10_mixed[0][0]           \n__________________________________________________________________________________________________\nblock35_10 (Lambda)             (None, 15, 25, 320)  0           block35_9_ac[0][0]               \n                                                                 block35_10_conv[0][0]            \n__________________________________________________________________________________________________\nblock35_10_ac (Activation)      (None, 15, 25, 320)  0           block35_10[0][0]                 \n__________________________________________________________________________________________________\nconv2d_479 (Conv2D)             (None, 15, 25, 256)  81920       block35_10_ac[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_479 (BatchN (None, 15, 25, 256)  768         conv2d_479[0][0]                 \n__________________________________________________________________________________________________\nactivation_479 (Activation)     (None, 15, 25, 256)  0           batch_normalization_479[0][0]    \n__________________________________________________________________________________________________\nconv2d_480 (Conv2D)             (None, 15, 25, 256)  589824      activation_479[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_480 (BatchN (None, 15, 25, 256)  768         conv2d_480[0][0]                 \n__________________________________________________________________________________________________\nactivation_480 (Activation)     (None, 15, 25, 256)  0           batch_normalization_480[0][0]    \n__________________________________________________________________________________________________\nconv2d_478 (Conv2D)             (None, 7, 12, 384)   1105920     block35_10_ac[0][0]              \n__________________________________________________________________________________________________\nconv2d_481 (Conv2D)             (None, 7, 12, 384)   884736      activation_480[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_478 (BatchN (None, 7, 12, 384)   1152        conv2d_478[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_481 (BatchN (None, 7, 12, 384)   1152        conv2d_481[0][0]                 \n__________________________________________________________________________________________________\nactivation_478 (Activation)     (None, 7, 12, 384)   0           batch_normalization_478[0][0]    \n__________________________________________________________________________________________________\nactivation_481 (Activation)     (None, 7, 12, 384)   0           batch_normalization_481[0][0]    \n__________________________________________________________________________________________________\nmax_pooling2d_10 (MaxPooling2D) (None, 7, 12, 320)   0           block35_10_ac[0][0]              \n__________________________________________________________________________________________________\nmixed_6a (Concatenate)          (None, 7, 12, 1088)  0           activation_478[0][0]             \n                                                                 activation_481[0][0]             \n                                                                 max_pooling2d_10[0][0]           \n__________________________________________________________________________________________________\nreshape (Reshape)               (None, 32, 2856)     0           mixed_6a[0][0]                   \n__________________________________________________________________________________________________\ndense1 (Dense)                  (None, 32, 32)       91424       reshape[0][0]                    \n__________________________________________________________________________________________________\ngru1 (GRU)                      (None, 32, 512)      838656      dense1[0][0]                     \n__________________________________________________________________________________________________\ngru1_b (GRU)                    (None, 32, 512)      838656      dense1[0][0]                     \n__________________________________________________________________________________________________\nadd_2 (Add)                     (None, 32, 512)      0           gru1[0][0]                       \n                                                                 gru1_b[0][0]                     \n__________________________________________________________________________________________________\ngru2 (GRU)                      (None, 32, 512)      1575936     add_2[0][0]                      \n__________________________________________________________________________________________________\ngru2_b (GRU)                    (None, 32, 512)      1575936     add_2[0][0]                      \n__________________________________________________________________________________________________\nconcatenate_2 (Concatenate)     (None, 32, 1024)     0           gru2[0][0]                       \n                                                                 gru2_b[0][0]                     \n__________________________________________________________________________________________________\ndense2 (Dense)                  (None, 32, 64)       65600       concatenate_2[0][0]              \n__________________________________________________________________________________________________\nsoftmax (Activation)            (None, 32, 64)       0           dense2[0][0]                     \n__________________________________________________________________________________________________\nthe_labels (InputLayer)         [(None, 16)]         0                                            \n__________________________________________________________________________________________________\ninput_length (InputLayer)       [(None, 1)]          0                                            \n__________________________________________________________________________________________________\nlabel_length (InputLayer)       [(None, 1)]          0                                            \n__________________________________________________________________________________________________\nctc (Lambda)                    (None, 1)            0           softmax[0][0]                    \n                                                                 the_labels[0][0]                 \n                                                                 input_length[0][0]               \n                                                                 label_length[0][0]               \n==================================================================================================\nTotal params: 9,328,448\nTrainable params: 4,986,208\nNon-trainable params: 4,342,240\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "get_model(True,145,220,3,64,16).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.zeros([32,75,75,3])\n",
    "model = tf.keras.applications.InceptionResNetV2(weights='imagenet', input_shape=(75,75,3), include_top=False)\n",
    "model.outputs = [model.get_layer('mixed_6a').output]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor 'mixed_6a_12/Identity:0' shape=(None, 3, 3, 1088) dtype=float32>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.applications.InceptionResNetV2(weights='imagenet', input_shape=(75,75,3), include_top=False)\n",
    "model.get_layer('mixed_6a').output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in converted code:\n\n    <ipython-input-34-97704c5aa866>:4 run_model  *\n        x = model(x)\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py:748 __call__\n        self._maybe_build(inputs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py:2116 _maybe_build\n        self.build(input_shapes)\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/core.py:1113 build\n        trainable=True)\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py:446 add_weight\n        caching_device=caching_device)\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/base.py:744 _add_variable_with_custom_getter\n        **kwargs_for_getter)\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer_utils.py:142 make_variable\n        shape=variable_shape if variable_shape else None)\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py:258 __call__\n        return cls._variable_v1_call(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py:219 _variable_v1_call\n        shape=shape)\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py:65 getter\n        return captured_getter(captured_previous, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py:502 invalid_creator_scope\n        \"tf.function-decorated function tried to create \"\n\n    ValueError: tf.function-decorated function tried to create variables on non-first call.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-97704c5aa866>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2360\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2362\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2363\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2703\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2705\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2593\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2595\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    976\u001b[0m                                           converted_func)\n\u001b[1;32m    977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in converted code:\n\n    <ipython-input-34-97704c5aa866>:4 run_model  *\n        x = model(x)\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py:748 __call__\n        self._maybe_build(inputs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py:2116 _maybe_build\n        self.build(input_shapes)\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/core.py:1113 build\n        trainable=True)\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py:446 add_weight\n        caching_device=caching_device)\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/base.py:744 _add_variable_with_custom_getter\n        **kwargs_for_getter)\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer_utils.py:142 make_variable\n        shape=variable_shape if variable_shape else None)\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py:258 __call__\n        return cls._variable_v1_call(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py:219 _variable_v1_call\n        shape=shape)\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py:65 getter\n        return captured_getter(captured_previous, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py:502 invalid_creator_scope\n        \"tf.function-decorated function tried to create \"\n\n    ValueError: tf.function-decorated function tried to create variables on non-first call.\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def run_model(x):\n",
    "    model = Dense(3, activation='relu', name='dense1')\n",
    "    x = model(x)\n",
    "    for i in range(3):\n",
    "        x = Dense(3, activation='relu', name='dense1')(x)\n",
    "    return x\n",
    "    \n",
    "\n",
    "\n",
    "x = tf.zeros([32,75,75,3])\n",
    "run_model(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust = CustomRNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}